{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff8a5465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import operator\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    counter: int\n",
    "    alphabet: list[str]\n",
    "\n",
    "\n",
    "def node_a(state: State):\n",
    "    state['counter'] += 1\n",
    "    state['alphabet'] = [\"Hello\"]\n",
    "    return state\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"Chatbot\", node_a)\n",
    "graph_builder.add_edge(START, \"Chatbot\")\n",
    "graph_builder.add_edge(\"Chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2125f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x10a986b10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9551a998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'counter': 1, 'alphabet': ['Hello']}\n",
      "{'counter': 2, 'alphabet': ['Hello']}\n",
      "{'counter': 3, 'alphabet': ['Hello']}\n"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    'counter': 0,\n",
    "    'alphabet': []\n",
    "}\n",
    "\n",
    "state = initial_state\n",
    "\n",
    "for _ in range(3):\n",
    "    state = graph.invoke(state)\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecd97350",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    counter: int\n",
    "    alphabet: Annotated[list[str], operator.add]\n",
    "\n",
    "def node_a(state: State):\n",
    "    state['counter'] += 1\n",
    "    state['alphabet'] = [\"Hello\"]\n",
    "    return state\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"Chatbot\", node_a)\n",
    "graph_builder.add_edge(START, \"Chatbot\")\n",
    "graph_builder.add_edge(\"Chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb52f887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'counter': 1, 'alphabet': ['Hello']}\n",
      "{'counter': 2, 'alphabet': ['Hello', 'Hello']}\n",
      "{'counter': 3, 'alphabet': ['Hello', 'Hello', 'Hello']}\n"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    'counter': 0,\n",
    "    'alphabet': []\n",
    "}\n",
    "\n",
    "state = initial_state\n",
    "\n",
    "for _ in range(3):\n",
    "    state = graph.invoke(state)\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d35b6a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "import os\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        api_key=os.environ.get(\"GOOGLE_API_KEY\"),\n",
    "        temperature=0,\n",
    "        max_tokens=1024,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "        disable_streaming=False,\n",
    "    )\n",
    "def chatbot(state: State):\n",
    "    response = llm.invoke(state['messages'])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"Chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"Chatbot\")\n",
    "graph_builder.set_finish_point(\"Chatbot\")\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b244a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x11aba2550>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01a2e0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: \n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79b10d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "import os\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph.message import MessagesState\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        api_key=os.environ.get(\"GOOGLE_API_KEY\"),\n",
    "        temperature=0,\n",
    "        max_tokens=1024,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "        disable_streaming=False,\n",
    "    )\n",
    "def chatbot(state: State):\n",
    "    response = llm.invoke(state['messages'])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"Chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"Chatbot\")\n",
    "graph_builder.set_finish_point(\"Chatbot\")\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "937966ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hi there! How can I help you today?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/najongseong/git_repository/teleai_lg/.venv/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:2316: UserWarning: HumanMessage with empty content was removed to prevent API error\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No content messages found. The Gemini API requires at least one non-system message (HumanMessage, AIMessage, etc.) in addition to any SystemMessage. Please include additional messages in your input.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_input.lower() == \u001b[33m\"\u001b[39m\u001b[33mexit\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAssistant:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/teleai_lg/.venv/lib/python3.11/site-packages/langgraph/pregel/main.py:2633\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2631\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2632\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2633\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2634\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2635\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2636\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2637\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2638\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2639\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2640\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2641\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2642\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2643\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/teleai_lg/.venv/lib/python3.11/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/teleai_lg/.venv/lib/python3.11/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/teleai_lg/.venv/lib/python3.11/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/teleai_lg/.venv/lib/python3.11/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mchatbot\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchatbot\u001b[39m(state: State):\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [response]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/teleai_lg/.venv/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:1962\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   1959\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1960\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1962\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/teleai_lg/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:382\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    368\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    370\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    375\u001b[39m     **kwargs: Any,\n\u001b[32m    376\u001b[39m ) -> AIMessage:\n\u001b[32m    377\u001b[39m     config = ensure_config(config)\n\u001b[32m    378\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    379\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    380\u001b[39m         cast(\n\u001b[32m    381\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    392\u001b[39m         ).message,\n\u001b[32m    393\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/teleai_lg/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1101\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1094\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1098\u001b[39m     **kwargs: Any,\n\u001b[32m   1099\u001b[39m ) -> LLMResult:\n\u001b[32m   1100\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/teleai_lg/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:911\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    908\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    909\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    910\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m911\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    913\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    914\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m         )\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    919\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/teleai_lg/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1205\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1203\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1204\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1205\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1209\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/teleai_lg/.venv/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:2083\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   2068\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   2069\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2070\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   2081\u001b[39m     **kwargs: Any,\n\u001b[32m   2082\u001b[39m ) -> ChatResult:\n\u001b[32m-> \u001b[39m\u001b[32m2083\u001b[39m     request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2084\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2085\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2086\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2087\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2088\u001b[39m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2089\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2090\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2091\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcached_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcached_content\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcached_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2092\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2093\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2094\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2095\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m   2096\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.timeout\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/teleai_lg/.venv/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:2338\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._prepare_request\u001b[39m\u001b[34m(self, messages, stop, tools, functions, safety_settings, tool_config, tool_choice, generation_config, cached_content, **kwargs)\u001b[39m\n\u001b[32m   2332\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m history:\n\u001b[32m   2333\u001b[39m     msg = (\n\u001b[32m   2334\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo content messages found. The Gemini API requires at least one \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2335\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mnon-system message (HumanMessage, AIMessage, etc.) in addition to \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2336\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33many SystemMessage. Please include additional messages in your input.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2337\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2338\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   2340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tool_choice:\n\u001b[32m   2341\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m formatted_tools:\n",
      "\u001b[31mValueError\u001b[39m: No content messages found. The Gemini API requires at least one non-system message (HumanMessage, AIMessage, etc.) in addition to any SystemMessage. Please include additional messages in your input.",
      "During task with name 'Chatbot' and id 'f6f14920-2a82-1099-a15b-d40fd406dd69'"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e8ed8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
